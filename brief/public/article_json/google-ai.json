{"site_name": "Wired", "description": "SEOUL, SOUTH KOREA \u2014 After more than four hours of tight play and a rapid-fire endgame, Google\u2019s artificially intelligent Go-playing computer system has won a second contest against grandmaster Lee Sedol, taking a two-games-to-none lead in their historic best-of-five match in downtown Seoul. The surprisingly skillful Google machine, known as AlphaGo, now needs only one more win to claim victory in the match. The Korean-born Lee Sedol will go down in defeat unless he takes each of the match\u2019s last three games. Though machines have beaten the best humans at chess, checkers, Othello, Scrabble, Jeopardy! , and so many other games considered tests of human intellect, they have never beaten the very best at Go. Game Three is set for Saturday afternoon inside Seoul\u2019s Four Seasons hotel. The match is a way of judging the suddenly rapid progress of artificial intelligence . One of the machine-learning techniques at the heart of AlphaGo has already reinvented myriad online services inside Google and other big-name Internet companies, helping to identify images, recognize commands spoken into smartphones, improve search engine results, and more. Meanwhile, another AlphaGo technique is now driving experimental robotics at Google and places like the University of California at Berkeley. This week\u2019s match can show how far these technologies have come\u2014and perhaps how far they will go. Created in Asia over 2,500 year ago, Go is exponentially more complex than chess, and at least among humans, it requires an added degree of intuition. Lee Sedol is widely-regarded as the top", "videos": [], "images": ["http://www.wired.com/wp-content/themes/Phoenix/assets/images/apple-touch-icon.png", "http://www.wired.com/wp-content/uploads/2016/03/GW201601310961-1024x768.jpg", "http://www.wired.com/wp-content/uploads/2016/03/GW20160132326-1024x768.jpg", "http://www.wired.com/wp-content/uploads/2016/03/GW20160131500-1024x768.jpg", "http://www.wired.com/wp-content/uploads/2016/03/GW201601310961-1024x768.jpg", "http://www.wired.com/wp-content/uploads/2016/03/GW20160132326-1024x768.jpg", "http://www.wired.com/wp-content/uploads/2016/03/GW20160131500-1024x768.jpg", "http://www.wired.com/wp-content/uploads/2016/04/voter-election-issues-509587438-600x450.jpg", "http://www.wired.com/wp-content/uploads/2016/04/army-drone-531583303-600x338.jpg", "http://www.wired.com/wp-content/uploads/2016/04/army-drone-531583303-200x200.jpg", "http://www.wired.com/wp-content/uploads/2016/03/GG3A0096_LR1-600x338-e1457763476548.jpg", "http://www.wired.com/wp-content/uploads/2016/03/GG3A0096_LR1-200x200-e1457763406708.jpg", "http://www.wired.com/wp-content/uploads/2016/04/IMG_6378-600x338.jpg", "http://www.wired.com/wp-content/uploads/2016/04/IMG_6378-150x150.jpg", "http://www.wired.com/wp-content/uploads/2016/04/alphabet-google-companies-anniversary-469919280-600x338-e1459468884707.jpg", "http://www.wired.com/wp-content/themes/Phoenix/assets/images/apple-touch-icon.png", "http://www.wired.com/wp-content/themes/Phoenix/assets/images/apple-touch-icon.png"], "words": 2116, "date": 1457568000.0, "title": "Google\u2019s AI Wins Pivotal Second Game in Match With Go Grandmaster", "url": "http://www.wired.com/2016/03/googles-ai-wins-pivotal-game-two-match-go-grandmaster/all/1", "is_rtl": false, "author": "Cade Metz", "html": "<article>\n\n\t\t\t<p>SEOUL, SOUTH KOREA \u2014 After more than four hours of tight play and a rapid-fire endgame, Google\u2019s artificially intelligent Go-playing computer system has won a second contest against grandmaster Lee Sedol, taking a two-games-to-none lead in their historic best-of-five match in downtown Seoul.</p>\n<p>The surprisingly skillful Google machine, known as AlphaGo, now needs only one more win to claim victory in the match. The Korean-born Lee Sedol will go down in defeat unless he takes each of the match\u2019s last three games. Though machines have beaten the best humans at chess, checkers, Othello, Scrabble, <em>Jeopardy!</em>, and so many other games considered tests of human intellect, they have never beaten the very best at Go. Game Three is set for Saturday afternoon inside Seoul\u2019s Four Seasons hotel.</p>\n<p>The match <a href=\"http://www.wired.com/2016/03/googles-ai-taking-one-worlds-top-go-players/\">is a way of judging the suddenly rapid progress of artificial intelligence</a>. One of the machine-learning techniques at the heart of AlphaGo <a href=\"http://www.wired.com/2015/04/jeff-dean/\">has already reinvented myriad online services inside Google</a> and other big-name Internet companies, helping to identify images, recognize commands spoken into smartphones, improve search engine results, and more. Meanwhile, another AlphaGo technique is now driving experimental robotics at Google and places like the University of California at Berkeley. This week\u2019s match can show how far these technologies have come\u2014and perhaps how far they will go. </p>\n<p>Created in Asia over 2,500 year ago, Go is exponentially more complex than chess, and at least among humans, it requires an added degree of intuition. Lee Sedol is widely-regarded as the top Go player of the last decade, after winning more international titles than all but one other player. He is currently ranked number five in the world, and according to Demis Hassabis, who leads DeepMind, the Google AI lab that created AlphaGo, his team chose the Korean for this all-important match because they wanted an opponent who would be remembered as one of history\u2019s great players. </p>\n<p>Although <a href=\"http://www.wired.com/2016/03/googles-ai-wins-first-game-historic-match-go-champion/\">AlphaGo topped Lee Sedol in the match\u2019s first game on Wednesday afternoon</a>, the outcome of Game Two was no easier to predict. <a href=\"https://en.wikipedia.org/wiki/Deep_Blue_versus_Garry_Kasparov\">In his 1996 match with IBM\u2019s Deep Blue supercomputer</a>, world chess champion Gary Kasparov lost the first game but then came back to win the second game and, eventually, the match as a whole. It wasn\u2019t until the following year that Deep Blue topped Kasparov over the course of a six-game contest. The thing to realize is that, after playing AlphaGo for the first time on Wednesday, Lee Sedol could adjust his style of play\u2014just as Kasparov did back in 1996. But AlphaGo could not. Because this Google creation relies so heavily on machine learning techniques, the DeepMind team needs a good four to six weeks to train a new incarnation of the system. And that means they can\u2019t really change things during this eight-day match.</p>\n<p>\u201cThis is about teaching and learning,\u201d Hassabis told us just before Game Two. \u201cOne game is not enough data to learn from\u2014for a machine\u2014and training takes an awful lot of time.\u201d</p>\n<figure><div>\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t</div><a href=\"http://www.wired.com/wp-content/uploads/2016/03/GW20160132326.jpg\"><img src=\"http://www.wired.com/wp-content/uploads/2016/03/GW20160132326-1024x768.jpg\"></a><figcaption>Lee Sedol seen on the front page of a Korean newspaper.  <span> Geordie Wood for WIRED</span></figcaption></figure>\n<h3>\u2018I Am In Shock\u2019</h3>\n<p>Following Game One, Lee Sedol acknowledged he was <a href=\"http://www.wired.com/2016/03/go-grandmaster-says-can-still-beat-googles-ai/\">\u201cshocked\u201d</a> by how well AlphaGo played and said he\u2019d made a notable mistake at the beginning of the game that led to his loss about three hours later. \u201cThe failure I made at the very beginning of the game lasted until the the very end,\u201d he said, through an interpreter. \u201cI didn\u2019t think that AlphaGo would play the game in such a perfect manner.\u201d It\u2019s unclear what early mistake he was referring to. The match\u2019s English language commentators didn\u2019t see one. But they do feel the Korean made a rather large error late in the game, following some particularly skillful play by AlphaGo. In any event, Lee Sedol did resolve to change his approach in Game Two.</p>\n<p>The added rub was that, after playing black in Game One, the Korean had to play white in Game Two. At the press conference following Game One, Lee Sedol gave himself a 50-50 chance in the second game\u2014a notable shift in attitude for the Go grandmaster, who was nothing less than adamant earlier in the week that he would defeat Google\u2019s artificially intelligent creation. \u201cI am in shock. I can admit that,\u201d Lee Sedol said after Game One. \u201cBut what\u2019s done is done.\u201d</p>\n<p>AlphaGo showed in the first game that it has a taste for the attack\u2014something it didn\u2019t necessarily show this past October, when it <a href=\"http://www.wired.com/2016/01/in-a-huge-breakthrough-googles-ai-beats-a-top-player-at-the-game-of-go/\">beat three-time European Go champion Fan Hui</a> during a closed-door match inside DeepMind headquarters. The question going into Game Two was whether it would attack just as aggressively when given the advantage of playing black.</p>\n<h3>Fast Versus Cautious</h3>\n<p>Attack it did. As commentator Michael Redmond put it, AlphaGo started \u201cfast,\u201d and seven moves in, the machine made what he called a \u201cslightly unusual move.\u201d He wasn\u2019t prepared to say whether it was a good move or a bad move, but it was aggressive, as if the machine was trying to force Lee Sedol into action. It soon made another move along the same lines.  </p>\n<p>But Lee Sedol didn\u2019t necessarily bite. At this point in the game, he took a rather long time considering his position and then continued with a comparatively cautious approach, according to Redmond. On the whole, Redmond said, the game was moving slower than it had at the same point in Game One. \u201cWhite is playing a much more conservative game,\u201d Redmond said, referring to Lee Sedol. Perhaps the Korean had adopted an added degree of caution after considering how well AlphaGo performed in Game One, but a certain amount of caution was expected because he was playing white, not black.</p>\n<p>Regardless, AlphaGo was showing\u2014once again\u2014that it\u2019s significantly more skilled than it was in October when it topped Fan Hui, the European Go champion who was ranked 633rd in the world at the time. For Redmond, the current version of AlphaGo not only plays more aggressively. It makes fewer mistakes.</p>\n<h3>\u2018A Creative Move\u2019</h3>\n<p>Then, with its 19th move, AlphaGo made an even more surprising and forceful play, dropping a black piece into some empty space on the right-hand side of the board. Lee Sedol seemed just as surprised as anyone else. He promptly left the match table, taking an (allowed) break as his game clock continued to run. \u201cIt\u2019s a creative move,\u201d Redmond said of AlphaGo\u2019s sudden change in tack. \u201cIt\u2019s something that I don\u2019t think I\u2019ve seen in a top player\u2019s game.\u201d</p>\n<p>When Lee Sedol returned to the match table, he took an usually long time to respond, his game clock running down to an hour and 19 minutes, a full twenty minutes less than the time left on AlphaGo\u2019s clock. \u201cHe\u2019s having trouble dealing with a move he has never seen before,\u201d Redmond said. But he also suspected that the Korean grandmaster was feeling a certain \u201cpleasure\u201d after the machine\u2019s big move. \u201cIt\u2019s something new and unique he has to think about,\u201d Redmond explained. \u201cThis is a reason people become pros.\u201d</p>\n<figure><div>\n\t\t\t\t\t\t\t\n\t\t\t\t\t\t\t</div><a href=\"http://www.wired.com/wp-content/uploads/2016/03/GW20160131500.jpg\"><img src=\"http://www.wired.com/wp-content/uploads/2016/03/GW20160131500-1024x768.jpg\"></a><figcaption>Commentator Michael Redmond.  <span> Geordie Wood for WIRED</span></figcaption></figure>\n<p>Back in 1997, during its second match with Gary Kasparov, IBM Deep Blue made a similar move very early in the second game. But it didn\u2019t give Kasparov much pleasure. Kasparov was completely flummoxed, and much to the surprise of the chess world, he soon resigned the game. It highlighted a certain advantage that machines carry in a match like this. They don\u2019t get upset. And they can rile opponents simply by doing something that no human would do\u2014or at least that no human would anticipate from a machine. \u201cComputers are able to make moves that are unexpected by people,\u201d says Murray Campbell, who was part of the team that built Deep Blue and is closely watching this week\u2019s match back in the States.</p>\n<h3>A New Autonomy</h3>\n<p>This is particularly true of AlphaGo, which is driven so heavily by machine learning\u2014technologies that allow it to learn tasks largely on its own. Hassabis and his team originally built AlphaGo using what are called deep neural networks, vast networks of hardware and software that mimic the web of neurons in the human brain. Essentially, they taught AlphaGo to play the game by feeding thousands upon thousands of human Go moves into these neural networks.</p>\n<p>But then, using a technique called reinforcement learning, they matched AlphaGo <em>against itself</em>. By playing match after match on its own, the system could learn to play at an even higher level\u2014perhaps at a level that eclipses the skills of any human. That\u2019s why it produces such unexpected moves.</p>\n<p>During Game One, match commentators Michael Redmond and Chris Garlock didn\u2019t seem to understand that AlphaGo operated in this way. Redmond kept referring to AlphaGo\u2019s \u201cdatabase\u201d of moves\u2014something it doesn\u2019t really have. Once the system is trained using those machine learning techniques, it plays entirely on its own. By Game Two, Redmond and Garlock were wise to this, after some coaching from the DeepMind team over breakfast here at the Four Seasons.</p>\n<p>During the match, the commentators even invited DeepMind research scientist Thore Graepel onto their stage to explain the system\u2019s rather autonomous nature. \u201cAlthough we have programmed this machine to play, we have no idea what moves it will come up with,\u201d Graepel said. \u201cIts moves are an emergent phenomenon from the training. We just create the data sets and the training algorithms. But the moves it then comes up with are out of our hands\u2014and much better than we, as Go players, could come up with.\u201d</p>\n<h3>Maximizing Probability</h3>\n<p>After AlphaGo\u2019s rather unexpected play on his 19th move, the Google machine was very much the aggressor. But then things tightened up, with Lee Sedol commanding some notable territory. Match commentators were unable to make a real call on who was ahead and who was behind.</p>\n<p>This reflects another aspect of the machine learning technology that underpins AlphaGo. As Graepel explained, AlphaGo does not attempt to maximize its points or its margin of victory. It tries to maximize its probability of winning. So, Graepel said, if AlphaGo must choose between a scenario where it will win by 20 points with 80 percent probability and another where it will win by 1 and a half points with 99 percent probability, it will choose the latter. Thus, late in Game One, the system made some moves that Redmond considered mistakes\u2014\u201cslow\u201d in his terminology. These moves seemed to give up points, but from where Graepel was sitting, AlphaGo was merely trying to maximize its chances. </p>\n<p>Near the two-hour mark in Game Two, Lee Sedol made a move in the top left-hand corner, at the heart of the territory commanded by AlphaGo, and Redmond said: \u201cThings are really going to get fun now.\u201d The Korean was back on the offensive, and Redmond predicted a \u201cclose game\u201d\u2014something he said so often during Game One. \u201cMy assessment will likely be changing,\u201d Redmond later said, \u201cwith every move.\u201d</p>\n<h3>Overtime at Speed</h3>\n<p>Unlike Game One, when Lee Sedol resigned after about three and a half hours, the Korean kept playing as the match approached its fourth hour. At the three and a half hour mark, Redmond felt that Lee Sedol might have a small territorial advantage. Shortly thereafter, the grandmaster\u2019s clock ran out, which meant he was forced to play each of his remaining moves in under 60 seconds. But Redmond believed that Lee Sedol had made most of his major decisions, and that he could easily play out the game at speed. </p>\n<p>The result was a rapid-fire end game. Lee Sedol began rocking back and forth in his chair during his first 60 seconds of overtime and continued to do so even after he made his move.  In terms of territory, the Korean seemed to hold his own. But time was indeed an issue. Twice, he let his 60 second clock run out (on the third time, he forfeits the game), an indication that we was still unsure how things should play out. \u201cI have a feeling\u2014and maybe Lee Sedol has a feeling\u2014that black is ahead,\u201d Redmond said.</p>\n<p>Lee Sedol started to rock again, and the other English commentator, Chris Garlock, insisted he saw sweat on the Korean\u2019s brow. Then the grandmaster began punctuating his moves with an almost despondent shaking of the head. As the match stretched well into its fourth hour, AlphaGo entered overtime as well, and both players were limited to 60 seconds per move. The pace picked up again, before only for so long. Just a few minutes later, Lee Sedol resigned.</p>\n<p>Friday is a rest day for the two players. That favors the Korean. And on Saturday, unlike today, he will play black and move first.</p>\n\n\t\t\t\n\n\t\t\t\n\t\t</article>\n\n\t\t", "thumbnail": "http://www.wired.com/wp-content/uploads/2016/03/GW20160130205-1200x630-e1458341802787.jpg"}