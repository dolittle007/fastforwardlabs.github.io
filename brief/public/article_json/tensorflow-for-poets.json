{"site_name": "petewarden.com", "description": "When I first started investigating the world of deep learning, I found it very hard to get started. There wasn\u2019t much documentation, and what existed was aimed at academic researchers who already knew a lot of the jargon and background. Thankfully that has changed over the last few years, with a lot more guides and tutorials appearing. I always loved EC2 for Poets though, and I haven\u2019t seen anything for deep learning that\u2019s aimed at as wide an audience. EC2 for Poets is an explanation of cloud computing that removes a lot of the unnecessary mystery by walking anyone with basic computing knowledge step-by-step through building a simple application on the platform. In the same spirit, I want to show how anyone with a Mac laptop and the ability to use the Terminal can create their own image classifier using TensorFlow , without having to do any coding. I feel very lucky to be a part of building TensorFlow , because it\u2019s a great opportunity to bring the power of deep learning to a mass audience. I look around and see so many applications that could benefit from the technology by understanding the images, speech, or text their users enter. The frustrating part is that deep learning is still seen as a very hard topic for product engineers to grasp. That\u2019s true at the cutting edge of research, but otherwise it\u2019s mostly a holdover from the early days. There\u2019s already a lot of great documentation on the TensorFlow site, but", "videos": ["http://www.youtube.com/embed/h7xuEiZjqqo?version=3&rel=1&fs=1&autohide=2&showsearch=0&showinfo=1&iv_load_policy=1&wmode=transparent"], "images": ["https://petewarden.files.wordpress.com/2016/02/screen-shot-2016-02-27-at-3-22-15-pm.png?w=550", "https://petewarden.files.wordpress.com/2016/02/screen-shot-2016-02-27-at-4-07-18-pm.png?w=550"], "words": 2079, "date": 1457246880.0, "title": "TensorFlow for Poets", "url": "http://petewarden.com/2016/02/28/tensorflow-for-poets/", "is_rtl": false, "author": "Pete Warden", "html": "<div>\n\t\t\t\t\t\t<p>When I first started investigating the world of deep learning, I found it very hard to get started. There wasn\u2019t much documentation, and what existed was aimed at academic researchers who already knew a lot of the jargon and background. Thankfully that has changed over the last few years, with a lot more guides and tutorials appearing.</p>\n<p>I always loved <a href=\"http://ec2.forpoets.org/\">EC2 for Poets</a> though, and I haven\u2019t seen anything for deep learning that\u2019s aimed at as wide an audience. EC2 for Poets is an explanation of cloud computing that removes a lot of the unnecessary mystery by walking anyone with basic computing knowledge step-by-step through building a simple application on the platform. In the same spirit, I want to show how anyone with a Mac laptop and the ability to use the Terminal can create their own image classifier using <a href=\"http://www.tensorflow.org/\">TensorFlow</a>, without having to do any coding.</p>\n<p>I feel very lucky to be a part of building <a href=\"http://www.tensorflow.org\">TensorFlow</a>, because it\u2019s a great opportunity to bring the power of deep learning to a mass audience. I look around and see so many applications that could benefit from the technology by understanding the images, speech, or text their users enter. The frustrating part is that deep learning is still seen as a very hard topic for product engineers to grasp. That\u2019s true at the cutting edge of research, but otherwise it\u2019s mostly a holdover from the early days. There\u2019s already a lot of great documentation on the <a href=\"http://www.tensorflow.org/\">TensorFlow</a> site, but to demonstrate how easy it can be for general software engineers to pick up I\u2019m going to present a walk-through that takes you from a clean OS X laptop all the way to classifying your own categories of images. You\u2019ll find written instructions in this post, along with <a href=\"https://www.youtube.com/watch?v=h7xuEiZjqqo\">a screencast showing exactly what I\u2019m doing</a>.</p>\n<p><span><div class=\"video_frame\"><iframe src=\"http://www.youtube.com/embed/h7xuEiZjqqo?version=3&amp;rel=1&amp;fs=1&amp;autohide=2&amp;showsearch=0&amp;showinfo=1&amp;iv_load_policy=1&amp;wmode=transparent\"></iframe></div></span></p>\n<h3>Docker</h3>\n<p>It\u2019s possible to get TensorFlow running natively on OS X, but there\u2019s less standardization around how the development tools like Python are installed which makes it hard to give one-size-fits-all instructions. To make life easier, I\u2019m going to use the free Docker container system, which will allow me to install a Linux virtual machine that runs on my MacBook Pro. The advantage is that I can start from a known system image, and so the instructions are a lot more likely to work for everyone.</p>\n<h3>Installing Docker</h3>\n<p>There\u2019s full documentation on installing Docker at <a href=\"https://docs.docker.com/mac/\">docker.com</a>, and it\u2019s likely to be updated over time, but I will run through exactly what steps I took to get it running here.</p>\n<ul>\n<li>I went to <a href=\"https://docs.docker.com/mac/\">docs.docker.com/mac/</a> in my browser.</li>\n<li><a href=\"https://docs.docker.com/mac/step_one/\">Step one</a> of the instructions sent me to <a href=\"https://www.docker.com/products/docker-toolbox\">download the Docker Toolbox</a>.</li>\n<li>On the Toolbox page, I clicked on the Mac download button.</li>\n<li>That downloaded a DockerToolbox-1.10.2.pkg file.</li>\n<li>I ran that downloaded pkg to install the Toolbox.</li>\n<li>At the end of the install process, I chose the Docker Quickstart Terminal.</li>\n<li>That opened up a new terminal window and ran through an installation script.</li>\n<li>At the end of the script, I saw ASCII art of a whale and I was left at a prompt.</li>\n<li>I went back to <a href=\"https://docs.docker.com/mac/step_one/\">step one</a> of the instructions, and ran the suggested command in the terminal:\n<pre><span>docker run hello-world</span></pre>\n</li>\n<li>This gave me output confirming my installation of Docker had worked:\n<pre>Hello from Docker.</pre>\n<pre>This message shows that your installation appears to be working correctly.</pre>\n</li>\n</ul>\n<h3>Installing TensorFlow</h3>\n<p>Now I\u2019ve got Docker installed and running, I can get a Linux virtual machine with TensorFlow pre-installed running. We create daily development images, and ones for every major release. Because the example code I\u2019m going to use came in after the last versioned release, 0.7.1, we\u2019ll have to do some extra work below to update the source code using git, but once 0.8 comes out you could replace the \u20180.7.1\u2019 below with the 0.8.0 instead, and skip the \u2018Updating the Code\u2019 section. <a href=\"https://www.tensorflow.org/versions/r0.7/get_started/os_setup.html#docker-installation\">The Docker section in the TensorFlow documentation</a> has more information.</p>\n<p>To download and run the TensorFlow docker image, use this command from the terminal:</p>\n<pre>docker run -it b.gcr.io/tensorflow/tensorflow:0.7.1-devel</pre>\n<p>This will show a series of download and extraction steps. These are the different components of the TensorFlow image being assembled. It needs to download roughly a gigabyte of data, so it can take a while on a slow network connection.</p>\n<p>Once that\u2019s complete, you\u2019ll find yourself in a new terminal. This is now actually the shell for the Linux virtual machine you\u2019ve downloaded. To confirm this has been successful, run this command:</p>\n<pre>ls /tensorflow</pre>\n<p>You should see a series of directories, including a tensorflow one and some .build files, something like this:</p>\n<p><img src=\"https://petewarden.files.wordpress.com/2016/02/screen-shot-2016-02-27-at-3-22-15-pm.png?w=550\"></p>\n<h3>Optimizing Docker</h3>\n<p>Often Docker is just used for testing web apps, where computational performance isn\u2019t that important, so the speed of the processor in the virtual machine isn\u2019t crucial. In our example we\u2019re going to be doing some very heavy number-crunching though, so optimizing the configuration for speed is important.</p>\n<p>Under the hood, Docker actually uses <a href=\"https://www.virtualbox.org/wiki/Downloads\">VirtualBox</a> to run its images, and we\u2019ll use its control panel to manage the setup. To do that, we\u2019ll need to take the following steps:</p>\n<ul>\n<li>Find the VirtualBox application on your Mac. I like to use spotlight to find and open it, so I don\u2019t have to hunt around on the file system.</li>\n<li>Once VirtualBox is open, you should see a left-hand pane showing virtual machines. There should be one called \u2018default\u2019 that\u2019s running.</li>\n<li>Right-click on \u2018default\u2019 to bring up the context menu and chose \u2018Close-&gt;ACPI Shutdown\u2019. The other close options should also work, but this is the most clean.</li>\n<li>Once the shutdown is complete, \u2018default\u2019 should have the text \u2018Powered off\u2019 below it. Right click on it again and choose \u2018Settings\u2026\u2019 from the menu.</li>\n<li>Click on the \u2018System\u2019 icon, and then choose the \u2018Motherboard\u2019 tab.</li>\n<li>Drag the \u2018Base Memory\u2019 slider as far as the green section goes, which is normally around 75% of your total laptop\u2019s memory. So in my case it\u2019s 12GB, because I have a 16GB machine.</li>\n<li>Click on the \u2018Processor\u2019 tab, and set the number of processors higher than the default of 1. Most likely on a modern MacBook Pro 4 is a good setting, but use the green bar below the slider as a guide.</li>\n<li>Click \u2018OK\u2019 on the settings dialog.</li>\n<li>Right-click on \u2018default\u2019 and choose \u2018Start-&gt;Headless Start\u2019.</li>\n</ul>\n<p>You should find that your terminal was kicked out of the Linux prompt when you stopped the \u2018default\u2019 box, but now you\u2019ve restarted it you can run the same command to access it again:</p>\n<pre>docker run -it b.gcr.io/tensorflow/tensorflow:0.7.1-devel</pre>\n<p>The only difference is that now the virtual machine will have access to a lot more of your laptop\u2019s computing power, and so the example should run a lot faster!</p>\n<h3>Downloading Images</h3>\n<p>The rest of this walk-through is based on <a href=\"https://www.tensorflow.org/versions/master/how_tos/image_retraining/index.html\">the image-retraining example on the TensorFlow site</a>. It shows you how to take your own images organized into folders by category, and use them to quickly retrain the top layer of the Inception image recognition neural network to recognize those categories. To get started, the first thing you need to do is get some example images. To begin, go to the terminal and enter the \u2018exit\u2019 command if you still see the \u2018root@\u2026\u2019 prompt that indicates you\u2019re still in the Linux virtual machine.</p>\n<p>Then run the following commands to create a new folder in your Downloads directory to hold training images, and download and extract the flower photos:</p>\n<pre>cd $HOME\nmkdir tf_files\ncd tf_files\ncurl -O http://download.tensorflow.org/example_images/flower_photos.tgz\ntar xzf flower_photos.tgz\nopen flower_photos</pre>\n<p>This should end up with a new finder window opening, showing a set of five folders:</p>\n<p><img src=\"https://petewarden.files.wordpress.com/2016/02/screen-shot-2016-02-27-at-4-07-18-pm.png?w=550\"></p>\n<p>This means you\u2019ve successfully downloaded the example flower images. If you look at how they\u2019re organized, you should be able to use the same structure with classes you care about, just replacing the folder names with the category labels you\u2019re dealing with, and populating them with photos of those objects. <a href=\"https://www.tensorflow.org/versions/master/how_tos/image_retraining/index.html#training-on-your-own-categories\">There\u2019s more guidance on that process in the tutorial</a>.</p>\n<h3>Running the VM with Shared Folders</h3>\n<p>Now you\u2019ve got some images to train with, we\u2019re going to start up the virtual machine again, this time sharing the folder you just created with Linux so TensorFlow can access the photos:</p>\n<pre>docker run -it -v $HOME/tf_files:/tf_files b.gcr.io/tensorflow/tensorflow:0.7.1-devel</pre>\n<p>You should find yourself back in a Linux prompt. To make sure the file sharing worked, try the following command:</p>\n<pre>ls /tf_files/flower_photos</pre>\n<p>You should see a list of the flower folders, like this:</p>\n<pre>root@2c570d651d08:~# ls /tf_files/flower_photos\nLICENSE.txt daisy dandelion roses sunflowers tulips\nroot@2c570d651d08:~#</pre>\n<h3>Updating the Code</h3>\n<p>For this example, we need the very latest code since it\u2019s just been added. Unfortunately getting it is a little involved, with some use of the source control program <a href=\"https://git-man-page-generator.lokaltog.net/\">git</a>. I\u2019ll walk through the steps below.</p>\n<p>Pulling the code requires a default email address, which you can set to anything, since we\u2019re not planning on pushing any changes back.</p>\n<pre>git config --global user.email \"you@example.com\"</pre>\n<pre>git config --global user.name \"Your Name\"</pre>\n<p>Now you should be able to pull the latest source.</p>\n<pre>cd /tensorflow/</pre>\n<pre>git pull origin master</pre>\n<p>You\u2019ll find yourself in a vim window. Just type \u2018:quit\u2019 to exit.</p>\n<p>You should now have fully up-to-date code. We want to sync it to a version we know works though, so we\u2019ll run this command:</p>\n<pre>git checkout 6d46c0b370836698a3195a6d73398f15fa44bcb2</pre>\n<h3>Building the Code</h3>\n<p>If that worked, the next step is to compile the code. You may notice there\u2019s some optimization flags in the command that help speed it up on processors with AVX, which almost all modern OS X machines have.</p>\n<pre>cd /tensorflow/\nbazel build -c opt --copt=-mavx tensorflow/examples/image_retraining:retrain</pre>\n<p>This part can take five to ten minutes, depending on the speed of your machine, as it\u2019s compiling the full source code for TensorFlow. Don\u2019t worry if you see a lot of warnings, this is normal (though we\u2019re working on reducing them going forward).</p>\n<h3>Running the Code</h3>\n<p>I can now run the retraining process using this command:</p>\n<pre>bazel-bin/tensorflow/examples/image_retraining/retrain \\\n--bottleneck_dir=/tf_files/bottlenecks \\\n--model_dir=/tf_files/inception \\\n--output_graph=/tf_files/retrained_graph.pb \\\n--output_labels=/tf_files/retrained_labels.txt \\\n--image_dir /tf_files/flower_photos</pre>\n<p>You\u2019ll see a message about downloading the Inception model, and then a long series of messages about creating bottlenecks. There\u2019s around 3,700 photos in total to process, and my machine does around 200 a minute, so it takes around twenty minutes in total. If you want to know more about what\u2019s happening under the hood while you wait, <a href=\"https://www.tensorflow.org/versions/master/how_tos/image_retraining/index.html#bottlenecks\">you can check out the tutorial for a detailed explanation</a>.</p>\n<p>I\u2019ve changed the default /tmp destination for things like the output graph and cached bottlenecks to the shared /tf_files folder, so that the results will be accessible from OS X and will be retained between different runs of the virtual machine.</p>\n<p>Once the bottlenecks are cached, it will then go into the training process, which takes another five minutes or so on my laptop. At the end, you should see the last output line giving the final estimated accuracy, which should be around 90%. That means you\u2019ve trained your classifier to guess the right flower species nine times out of ten when shown a photo!</p>\n<h3>Using the Classifier</h3>\n<p>The training process outputs the retrained graph into /tmp/output_graph.pb, and to test it out yourself you can build another piece of sample code. The <a href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/label_image\">label_image example</a> is a small C++ program that loads in a graph and applies it to a user-supplied image. Give it a try like this:</p>\n<pre>bazel build tensorflow/examples/label_image:label_image &amp;&amp; \\\nbazel-bin/tensorflow/examples/label_image/label_image \\\n--graph=/tf_files/retrained_graph.pb \\\n--labels=/tf_files/retrained_labels.txt \\\n--output_layer=final_result \\\n--image=/tf_files/flower_photos/daisy/21652746_cc379e0eea_m.jpg</pre>\n<p>You should see a result showing that it identified a daisy in that picture, though because the training process is random you may occasionally have a model that makes a mistak on the image. Try it with some of the other photos to get a feel for how it\u2019s doing.</p>\n<h3>Next Steps</h3>\n<p>The first thing you\u2019ll probably want to do is train a classifier for objects you care about in your application. This should be as simple as creating a new folder in your Downloads/tf_images directory, putting subfolders full of photos in it, and re-running the classifier commands. You can find more detailed advice on tuning that process <a href=\"https://www.tensorflow.org/versions/master/how_tos/image_retraining/index.html#training-on-your-own-categories\">in the tutorial</a>.</p>\n<p>Finally, you\u2019ll want to use this in your own application! The <a href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/label_image\">label_image example</a> is a good template to look at if you can integrate C++ into your product, and we even support running on mobile, so check out t<a href=\"https://github.com/tensorflow/tensorflow/tree/master/tensorflow/examples/android\">he Android sample code</a> if you\u2019d like to run on a smart phone.</p>\n<p>Thanks for working through this process with me, I hope it\u2019s inspired you to think about how you can use deep learning to help your users, and I can\u2019t wait to see what you build!</p>\n\t\t\t\t\t</div>\n\t", "thumbnail": "https://petewarden.files.wordpress.com/2016/02/screen-shot-2016-02-27-at-4-07-18-pm.png"}